[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Lab",
    "section": "",
    "text": "Interests: cross-modal neural networks, execution graphs, context-orchestration and small language model intersections"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "AI Experiments",
    "section": "",
    "text": "Here is a list of my repositories:\n\nCDLL\nCNN-for-Text-Classification\nK-Nearest-Neighbor"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my AI Lab",
    "section": "",
    "text": "This is a proof-of-concept post demonstrating scientific publishing capabilities with Quarto."
  },
  {
    "objectID": "posts/welcome/index.html#mathematical-formulation",
    "href": "posts/welcome/index.html#mathematical-formulation",
    "title": "Welcome to my AI Lab",
    "section": "Mathematical Formulation",
    "text": "Mathematical Formulation\nWe can render complex equations using LaTeX. For example, the Cross-Entropy Loss function:\n\nL_{CE} = - \\sum_{i=1}^{C} t_i \\log(p_i)\n\nWhere: - t_i is the truth label. - p_i is the Softmax probability for the i^{th} class."
  },
  {
    "objectID": "posts/welcome/index.html#architecture-diagram",
    "href": "posts/welcome/index.html#architecture-diagram",
    "title": "Welcome to my AI Lab",
    "section": "Architecture Diagram",
    "text": "Architecture Diagram\nHere is a simple Neural Network visualizations using Mermaid.js:\n\n\n\n\n\ngraph LR\n    A[Input Layer] --&gt; B(Hidden Layer)\n    B --&gt; C{Activation}\n    C --&gt; D[Output Layer]\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style D fill:#ccf,stroke:#333,stroke-width:2px"
  },
  {
    "objectID": "posts/welcome/index.html#implementation",
    "href": "posts/welcome/index.html#implementation",
    "title": "Welcome to my AI Lab",
    "section": "Implementation",
    "text": "Implementation\nBelow is a PyTorch tensor initialization:\nimport torch\n\n# Define a simple tensor\nx = torch.tensor([[1, 2], [3, 4]])\nprint(f\"Tensor shape: {x.shape}\")"
  },
  {
    "objectID": "index.html#latest-research",
    "href": "index.html#latest-research",
    "title": "Welcome to the Lab",
    "section": "Latest Research",
    "text": "Latest Research"
  },
  {
    "objectID": "work/projects/index.html",
    "href": "work/projects/index.html",
    "title": "AI Experiments",
    "section": "",
    "text": "Here is a list of my repositories:\n\nCDLL\nCNN-for-Text-Classification\nK-Nearest-Neighbor"
  },
  {
    "objectID": "work/research/index.html",
    "href": "work/research/index.html",
    "title": "Research",
    "section": "",
    "text": "Context State Decoupling\n\n\nDissociating Logical State from Ephemeral Inference\n\n\n\nReasoning\n\n\nArchitecture\n\n\nSLM\n\n\n\n\n\n\n\n\n\nJan 4, 2026\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "work/research/reasoning/context-state-decoupling/index.html",
    "href": "work/research/reasoning/context-state-decoupling/index.html",
    "title": "Context State Decoupling",
    "section": "",
    "text": "In the current paradigm of Large Language Model (LLM) architecture, “intelligence” is strictly bound by the context window. To reason about a sequence of length N, the model must load all N tokens into its active attention mechanism.\nThis creates a fundamental scaling paradox: \n\\text{Cost} \\propto O(N^2)\n\nAs the history H grows, the cost to generate the next token t_{n+1} increases quadratically (or linearly with optimized attention, but still creating massive memory pressure). This forces a “Sliding Window” approach, where older context is lobotomized to make room for new data, destroying the continuity of the system’s “self”."
  },
  {
    "objectID": "work/research/reasoning/context-state-decoupling/index.html#the-linear-paradox",
    "href": "work/research/reasoning/context-state-decoupling/index.html#the-linear-paradox",
    "title": "Context State Decoupling",
    "section": "",
    "text": "In the current paradigm of Large Language Model (LLM) architecture, “intelligence” is strictly bound by the context window. To reason about a sequence of length N, the model must load all N tokens into its active attention mechanism.\nThis creates a fundamental scaling paradox: \n\\text{Cost} \\propto O(N^2)\n\nAs the history H grows, the cost to generate the next token t_{n+1} increases quadratically (or linearly with optimized attention, but still creating massive memory pressure). This forces a “Sliding Window” approach, where older context is lobotomized to make room for new data, destroying the continuity of the system’s “self”."
  },
  {
    "objectID": "work/research/reasoning/context-state-decoupling/index.html#the-decoupling-thesis",
    "href": "work/research/reasoning/context-state-decoupling/index.html#the-decoupling-thesis",
    "title": "Context State Decoupling",
    "section": "2. The Decoupling Thesis",
    "text": "2. The Decoupling Thesis\nWe propose a neuro-symbolic architecture that solves this by functionally identifying and separating two distinct cognitive processes:\n\nLogical State (Hippocampus): The persistent, evolving graph of facts, events, and their causal relationships.\nEphemeral Inference (Prefrontal Cortex): The active processing unit that synthesizes updates to the state.\n\nBy decoupling these components, we can achieve “Infinite Context” without infinite compute. The LLM no longer needs to hold the state; it only needs to navigate it."
  },
  {
    "objectID": "work/research/reasoning/context-state-decoupling/index.html#graph-topology-as-memory",
    "href": "work/research/reasoning/context-state-decoupling/index.html#graph-topology-as-memory",
    "title": "Context State Decoupling",
    "section": "3. Graph Topology as Memory",
    "text": "3. Graph Topology as Memory\nInstead of a linear stream of tokens, the conversation state is stored as a Directed Acyclic Graph (DAG) in a persistent Vector Database.\n\n\n\nFigure 1: Context State DAG Topology. Visualizing the atomic segmentation of user intent into persistent graph nodes.\n\n\nEach node in this graph represents an atomic “Context Block”—a semantically segmented unit of intent—rather than a raw token chunk."
  },
  {
    "objectID": "work/research/reasoning/context-state-decoupling/index.html#neuro-symbolic-retrieval",
    "href": "work/research/reasoning/context-state-decoupling/index.html#neuro-symbolic-retrieval",
    "title": "Context State Decoupling",
    "section": "4. Neuro-Symbolic Retrieval",
    "text": "4. Neuro-Symbolic Retrieval\nWhen the system receives a new input I_t, it does not blindly feed the previous N tokens into the context window. Instead, it performs a hybrid retrieval operation to construct a Localized Context:\n\nC_{local} = \\text{Top}_k(Sim(I_t, \\text{Graph})) \\cup \\text{Neighbors}(\\text{Top}_k)\n\nThis ensures that the LLM’s working memory usage remains constant (O(k)) regardless of the total conversation length (N).\n\n4.1 The Cognitive Loop\n\nSegmentation: Input is broken into atomic intents.\nRetrieval: Relevant historical nodes are fetched from the Graph.\nSynthesis: The SLM, acting as a kernel, generates the next reasoning step.\nUpdate: The new reasoning is appended to the Graph as a new Node, permanently updating the “Long-Term Memory”.\n\nThis architecture allows small, efficient models (SLMs) to exhibit coherent long-term reasoning by offloading the burden of “remembering” to a structured, symbolic substrate."
  }
]